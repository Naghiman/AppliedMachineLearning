{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\\ Import libraries and dataset\n"
    }
   },
   "outputs": [],
   "source": [
    "import h5py as h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "# ! wget https://drive.google.com/file/d/1LcKqf1d7bctw5lx0YZf31kCUF0zEYOsi/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: torch.Size([56000, 1, 64, 64]), dtype torch.uint8\n",
      "y_train.shape: torch.Size([56000, 5]), dtype torch.int32\n",
      "X_test.shape: torch.Size([14000, 1, 64, 64]), dtype torch.uint8\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('MNIST_synthetic.h5', 'r')\n",
    "\n",
    "X_train = torch.tensor(f['train_dataset'][...]).permute(0, 3, 1, 2).contiguous()\n",
    "y_train = torch.tensor(f['train_labels'][...])\n",
    "X_test = torch.tensor(f['test_dataset'][...]).permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "# These are the tensors for our 2nd CNN which predicts the number of digits in an image\n",
    "X_train2 = torch.tensor(f['train_dataset'][...])\n",
    "y_train2 = torch.tensor(f['train_labels'][...])\n",
    "X_test2 = torch.tensor(f['test_dataset'][...])\n",
    "\n",
    "\n",
    "# can refactor to map lambda, same performance\n",
    "def count_digits(tensor):\n",
    "    counter = 0\n",
    "    for i,t in enumerate(tensor):\n",
    "        if tensor[i] != 10:\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "\n",
    "def count_num_digits(labels):\n",
    "    new_labels = torch.empty(len(y_train2), 1 , dtype=torch.int32)\n",
    "    for i,t in enumerate(labels):\n",
    "        new_labels[i] = count_digits(t)\n",
    "    return new_labels\n",
    "\n",
    "num_of_digits = count_num_digits(y_train2)\n",
    "\n",
    "\n",
    "print(f'X_train.shape: {X_train.shape}, dtype {X_train.dtype}')\n",
    "print(f'y_train.shape: {y_train.shape}, dtype {y_train.dtype}')\n",
    "print(f'X_test.shape: {X_test.shape}, dtype {X_test.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scale(tensor):\n",
    "    \"\"\"\n",
    "    [0, 255] -> [-1, 1]\n",
    "    \"\"\"\n",
    "    return (tensor.to(torch.float32) * 2 / 255) - 1\n",
    "\n",
    "def descale(tensor):\n",
    "    \"\"\"\n",
    "    [-1, 1] -> [0, 255]\n",
    "    \"\"\"\n",
    "    return ((tensor + 1) * 255 / 2).to(torch.uint8)\n",
    "\n",
    "def visualize_tensor(tensor):\n",
    "    \"\"\"\n",
    "    visualize a tensor of shape (H, W, 1). Must be in range [-1, 1] or [0, 255].\n",
    "    \"\"\"\n",
    "    if tensor.dtype == torch.float32:\n",
    "        tensor = descale(tensor)\n",
    "    array = tensor.permute(1, 2, 0).contiguous().numpy()\n",
    "    plt.imshow(array, cmap='Greys_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 61)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"<tokenize>\"\u001B[1;36m, line \u001B[1;32m61\u001B[0m\n\u001B[1;33m    def __getitem__(self, index):\u001B[0m\n\u001B[1;37m    ^\u001B[0m\n\u001B[1;31mIndentationError\u001B[0m\u001B[1;31m:\u001B[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "digit_size = 12  # 64 // 5\n",
    "crop_h_start = (64 // 2) - (digit_size // 2)\n",
    "crop_h_end = crop_h_start + digit_size +1  # +1 is safety margin\n",
    "crop_w_start = 2\n",
    "crop_w_end = -2\n",
    "\n",
    "def split_digits(tensor, num_digits, digit_size=digit_size):\n",
    "    \"\"\"\n",
    "    splits a single image of `num_digits` digits to multiple images\n",
    "    \"\"\"\n",
    "    start_index = (5 - num_digits) * digit_size // 2\n",
    "    end_index = start_index + (num_digits * digit_size)\n",
    "    tensor = tensor[..., start_index: end_index]\n",
    "    return torch.stack(torch.chunk(tensor, num_digits, dim=2))\n",
    "\n",
    "# remove padding and rescale\n",
    "X_train_processed = scale(X_train[..., crop_h_start: crop_h_end, crop_w_start: crop_w_end])\n",
    "y_train_processed = y_train.to(torch.int64)\n",
    "X_test_processed = scale(X_test[..., crop_h_start: crop_h_end, crop_w_start: crop_w_end])\n",
    "\n",
    "\n",
    "# TODO: Create validation set randomly (with a fixed random seed) and val_loader\n",
    "num_digits_train_dataset = None\n",
    "num_digits_train_loader = None\n",
    "num_digits_val_dataset = None\n",
    "num_digits_val_loader = None\n",
    "\"\"\"\n",
    "dataset = TensorDataset(X_train_processed, y_train_processed)\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\"\"\"\n",
    "\n",
    "# TODO: create a new dataset and loader from the previous dataset by splitting all digits and stacking them all together\n",
    "# such that the new dataset is of shape (number of total digits x 1 x 28 x 28)\n",
    "digits_train_dataset = None\n",
    "digits_train_loader = None\n",
    "digits_val_dataset = None\n",
    "digits_val_loader = None\n",
    "\n",
    "test_loader = DataLoader(X_test_processed, batch_size=4)\n",
    "\n",
    "# Class to represent our dataset and be used with dataloader\n",
    "class CustomMNISTDataset(TensorDataset):\n",
    "    def __init__(self):\n",
    "        self.len = len(X_train_processed)\n",
    "        self.x_data = X_train_processed\n",
    "        self.y_data = y_train_processed\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Class for our second CNN to predict the number of digits in an iamge\n",
    "class NumberOfDigitsDataset(TensorDataset):\n",
    "    def __init__(self):\n",
    "        self.len = len(X_train)\n",
    "        self.x_data = X_train2\n",
    "        self.y_data = num_of_digits\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "dataset = CustomMNISTDataset()\n",
    "dataset2 = NumberOfDigitsDataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "train_loader2= torch.utils.data.DataLoader(dataset=dataset2, batch_size=4,\n",
    "                                          shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw X_train\n",
      "------\n",
      "\n",
      "Preprocessed X_train\n",
      "Label: tensor([ 9, 10, 10, 10, 10])\n",
      "Splitted\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Raw X_train')\n",
    "visualize_tensor(X_train[102])\n",
    "print('------\\n')\n",
    "print('Preprocessed X_train')\n",
    "x_sample, y_sample = next(iter(train_loader))\n",
    "print(f'Label: {y_sample[0]}')\n",
    "visualize_tensor(x_sample[0])\n",
    "print('Splitted')\n",
    "num_digits = torch.sum(y_sample[0] != 10).item()\n",
    "splitted_digits = split_digits(x_sample[0], num_digits)\n",
    "for digit in splitted_digits:\n",
    "    visualize_tensor(digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Convolutional neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# TODO: STEP 1\n",
    "# Train a NN to predict num_digits in each sample. I.e. input would be X from num_digits_train_dataset, output would be\n",
    "# torch.sum(y[0] != 10).item()\n",
    "# This model should have accuracy very close to 100% (>99% on validation)\n",
    "# IF IT DOESN'T, MIGHT NEED DATA AUGMENTATION HERE\n",
    "# Track validation accuracy during training to avoid overfitting (stop training when\n",
    "# validation accuracy starts to decrease)\n",
    "# FANCY TIPS: Use batchnorm layers, lookup VGG/RESNET architecture\n",
    "\n",
    "# TODO: STEP 2\n",
    "# Train a NN to predict each 12x12 digit in digits_train_dataset\n",
    "# Track validation accuracy during training to avoid overfitting (stop training when\n",
    "# validation accuracy starts to decrease)\n",
    "# FANCY TIPS: Use batchnorm layers, lookup VGG/RESNET architecture\n",
    "\n",
    "# TODO: STEP 3\n",
    "# Make num_digits prediction for X_test based on model in STEP1, then use `split_digits()` function \n",
    "# with the predicted number of digits to split the digits, then make a prediction for each digit\n",
    "# separately by using the model trained in STEP 2. Convert the predictions from e.g. 2, 3\n",
    "# into the required format e.g. [2, 3, 10, 10, 10]\n",
    "\n",
    "# TODO: STEP 4\n",
    "# Convert predictions into whatever Excel format is required for uploading to Kaggle\n",
    "\n",
    "# TODO: EXTRA IMPROVEMENTS\n",
    "# - Data Augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Flatten(start_dim=1, end_dim=-1)\n",
      "  (4): Linear(in_features=1080, out_features=120, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=84, out_features=55, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0) # Ensure model weights initialized with same random numbers\n",
    "\n",
    "# # model 0\n",
    "# num_filters = 8\n",
    "# filter_size = 5\n",
    "# pool_size = 4\n",
    "\n",
    "# model = torch.nn.Sequential(\n",
    "#     torch.nn.Conv2d(in_channels=1,\n",
    "#                     out_channels=num_filters,\n",
    "#                     kernel_size=filter_size,\n",
    "#                     padding=filter_size // 2),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "#     torch.nn.Flatten(),\n",
    "#     torch.nn.Linear(num_filters * 64**2 // pool_size**2, 10),\n",
    "# )\n",
    "\n",
    "\n",
    "# model 1\n",
    "num_filters = [6, 16]\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "mlp_size = [16*14*14, 120, 84, 5 * 11]\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1,\n",
    "                    out_channels=num_filters[0],\n",
    "                    kernel_size=filter_size,\n",
    "                    padding=filter_size // 2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "    # torch.nn.Conv2d(in_channels=num_filters[0],\n",
    "    #                 out_channels=num_filters[1],\n",
    "    #                 kernel_size=filter_size,\n",
    "    #                 padding=filter_size // 2),\n",
    "    # torch.nn.ReLU(),\n",
    "    # torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(1080, mlp_size[1]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(mlp_size[1], mlp_size[2]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(mlp_size[2], mlp_size[3]),\n",
    ")\n",
    "\n",
    "\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loss function and Optimizer\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# cross entropy is pretty good for classification problems\n",
    "# discuss pros of cross entropy in the report\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# might need to play a bit with learning rate and momentum if needed\n",
    "# SGD is computationally efficient\n",
    "# GD is terrible, uses too much memory\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters())  # converges faster and less sensitive to lr, generalizes (typiaclly) worse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training CNN\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000 loss: 6.297\n",
      "[1,  4000 loss: 4.130\n",
      "[1,  6000 loss: 3.285\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-11-0b00d19462fc>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# computing gradients wrt model's weights\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# update using learning rate\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[1;31m# print statistics\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 26\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     27\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mF\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\torch\\optim\\adam.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    106\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    107\u001B[0m             \u001B[0mbeta1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbeta2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgroup\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'betas'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 108\u001B[1;33m             F.adam(params_with_grad,\n\u001B[0m\u001B[0;32m    109\u001B[0m                    \u001B[0mgrads\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m                    \u001B[0mexp_avgs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\torch\\optim\\functional.py\u001B[0m in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001B[0m\n\u001B[0;32m     92\u001B[0m             \u001B[0mdenom\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mmax_exp_avg_sq\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mmath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbias_correction2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0meps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 94\u001B[1;33m             \u001B[0mdenom\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mexp_avg_sq\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mmath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbias_correction2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0meps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     95\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     96\u001B[0m         \u001B[0mstep_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlr\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mbias_correction1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# loop over dataset multiple times\n",
    "# model.train()\n",
    "for epoch in range(4):\n",
    "    running_loss = 0 # counter\n",
    "    # get inputs, data is a list of [inputs, labels]\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        # loss = criterion(outputs, labels)\n",
    "        loss = 0\n",
    "        for j in range(5):\n",
    "            loss += criterion(outputs[:, (j * 11):((j + 1) * 11)], labels[:, j])\n",
    "\n",
    "        loss.backward() # computing gradients wrt model's weights\n",
    "        optimizer.step() # update using learning rate\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # print every 2000 minibatches\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss/2000))\n",
    "            running_loss = 0\n",
    "\n",
    "print('Done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_input = next(iter(test_loader))\n",
    "test_output = model(test_input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def output_to_label(output):\n",
    "    labels = [torch.argmax(output[:, (j * 11):((j + 1) * 11)], dim=1) for j in range(5)]\n",
    "    return torch.stack(labels)\n",
    "test_pred_labels = output_to_label(test_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_pred_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0) # Ensure model weights initialized with same random numbers\n",
    "\n",
    "# # model 0\n",
    "# num_filters = 8\n",
    "# filter_size = 5\n",
    "# pool_size = 4\n",
    "\n",
    "# model = torch.nn.Sequential(\n",
    "#     torch.nn.Conv2d(in_channels=1,\n",
    "#                     out_channels=num_filters,\n",
    "#                     kernel_size=filter_size,\n",
    "#                     padding=filter_size // 2),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "#     torch.nn.Flatten(),\n",
    "#     torch.nn.Linear(num_filters * 64**2 // pool_size**2, 10),\n",
    "# )\n",
    "\n",
    "\n",
    "# model 1\n",
    "num_filters = [6, 16]\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "mlp_size = [4096, 120, 84, 5 * 11]\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1,\n",
    "                    out_channels=num_filters[0],\n",
    "                    kernel_size=filter_size,\n",
    "                    padding=filter_size // 2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "    torch.nn.Conv2d(in_channels=num_filters[0],\n",
    "                    out_channels=num_filters[1],\n",
    "                    kernel_size=filter_size,\n",
    "                    padding=filter_size // 2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(720, mlp_size[1]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(mlp_size[1], mlp_size[2]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(mlp_size[2], mlp_size[3]),\n",
    ")\n",
    "\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loss function and Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy is pretty good for classification problems\n",
    "# discuss pros of cross entropy in the report\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# might need to play a bit with learning rate and momentum if needed\n",
    "# SGD is computationally efficient\n",
    "# GD is terrible, uses too much memory\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters())  # converges faster and less sensitive to lr, generalizes (typiaclly) worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop over dataset multiple times\n",
    "# model.train()\n",
    "for epoch in range(4):\n",
    "    running_loss = 0 # counter\n",
    "    # get inputs, data is a list of [inputs, labels]\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        # loss = criterion(outputs, labels)\n",
    "        loss = 0\n",
    "        for j in range(5):\n",
    "            loss += criterion(outputs[:, (j * 11):((j + 1) * 11)], labels[:, j])\n",
    "\n",
    "        loss.backward() # computing gradients wrt model's weights\n",
    "        optimizer.step() # update using learning rate\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # print every 2000 minibatches\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss/2000))\n",
    "            running_loss = 0\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_input = next(iter(test_loader))\n",
    "test_output = model(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_label(output):\n",
    "    labels = [torch.argmax(output[:, (j * 11):((j + 1) * 11)], dim=1) for j in range(5)]\n",
    "    return torch.stack(labels)\n",
    "test_pred_labels = output_to_label(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs, labels\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}