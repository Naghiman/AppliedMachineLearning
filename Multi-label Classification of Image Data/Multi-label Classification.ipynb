{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\\ Import libraries and dataset\n"
    }
   },
   "outputs": [],
   "source": [
    "import h5py as h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "# ! wget https://drive.google.com/file/d/1LcKqf1d7bctw5lx0YZf31kCUF0zEYOsi/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: torch.Size([56000, 1, 64, 64]), dtype torch.uint8\n",
      "y_train.shape: torch.Size([56000, 5]), dtype torch.int32\n",
      "X_test.shape: torch.Size([14000, 1, 64, 64]), dtype torch.uint8\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('MNIST_synthetic.h5', 'r')\n",
    "\n",
    "X_train = torch.tensor(f['train_dataset'][...]).permute(0, 3, 1, 2).contiguous()\n",
    "y_train = torch.tensor(f['train_labels'][...])\n",
    "X_test = torch.tensor(f['test_dataset'][...]).permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "# These are the tensors for our 2nd CNN which predicts the number of digits in an image\n",
    "X_train2 = torch.tensor(f['train_dataset'][...]).permute(0, 3, 1, 2).contiguous()\n",
    "y_train2 = torch.tensor(f['train_labels'][...])\n",
    "X_test2 = torch.tensor(f['test_dataset'][...])\n",
    "\n",
    "\n",
    "# can refactor to map lambda, same performance\n",
    "def count_digits(tensor):\n",
    "    counter = 0\n",
    "    for i,t in enumerate(tensor):\n",
    "        if tensor[i] != 10:\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "\n",
    "def count_num_digits(labels):\n",
    "    new_labels = torch.empty(len(y_train2), 1 , dtype=torch.int32)\n",
    "    for i,t in enumerate(labels):\n",
    "        new_labels[i] = count_digits(t)\n",
    "    return new_labels\n",
    "\n",
    "num_of_digits = count_num_digits(y_train2)\n",
    "\n",
    "\n",
    "print(f'X_train.shape: {X_train.shape}, dtype {X_train.dtype}')\n",
    "print(f'y_train.shape: {y_train.shape}, dtype {y_train.dtype}')\n",
    "print(f'X_test.shape: {X_test.shape}, dtype {X_test.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scale(tensor):\n",
    "    \"\"\"\n",
    "    [0, 255] -> [-1, 1]\n",
    "    \"\"\"\n",
    "    return (tensor.to(torch.float32) * 2 / 255) - 1\n",
    "\n",
    "def descale(tensor):\n",
    "    \"\"\"\n",
    "    [-1, 1] -> [0, 255]\n",
    "    \"\"\"\n",
    "    return ((tensor + 1) * 255 / 2).to(torch.uint8)\n",
    "\n",
    "def visualize_tensor(tensor):\n",
    "    \"\"\"\n",
    "    visualize a tensor of shape (H, W, 1). Must be in range [-1, 1] or [0, 255].\n",
    "    \"\"\"\n",
    "    if tensor.dtype == torch.float32:\n",
    "        tensor = descale(tensor)\n",
    "    array = tensor.permute(1, 2, 0).contiguous().numpy()\n",
    "    plt.imshow(array, cmap='Greys_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13, 60])\n",
      "torch.Size([1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "digit_size = 12  # 64 // 5\n",
    "crop_h_start = (64 // 2) - (digit_size // 2)\n",
    "crop_h_end = crop_h_start + digit_size +1  # +1 is safety margin\n",
    "crop_w_start = 2\n",
    "crop_w_end = -2\n",
    "\n",
    "def split_digits(tensor, num_digits, digit_size=digit_size):\n",
    "    \"\"\"\n",
    "    splits a single image of `num_digits` digits to multiple images\n",
    "    \"\"\"\n",
    "    start_index = (5 - num_digits) * digit_size // 2\n",
    "    end_index = start_index + (num_digits * digit_size)\n",
    "    tensor = tensor[..., start_index: end_index]\n",
    "    return torch.stack(torch.chunk(tensor, num_digits, dim=2))\n",
    "\n",
    "# remove padding and rescale\n",
    "X_train_processed = scale(X_train[..., crop_h_start: crop_h_end, crop_w_start: crop_w_end])\n",
    "y_train_processed = y_train.to(torch.int64)\n",
    "X_test_processed = scale(X_test[..., crop_h_start: crop_h_end, crop_w_start: crop_w_end])\n",
    "\n",
    "\n",
    "# TODO: Create validation set randomly (with a fixed random seed) and val_loader\n",
    "num_digits_train_dataset = None\n",
    "num_digits_train_loader = None\n",
    "num_digits_val_dataset = None\n",
    "num_digits_val_loader = None\n",
    "\"\"\"\n",
    "dataset = TensorDataset(X_train_processed, y_train_processed)\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\"\"\"\n",
    "\n",
    "# TODO: create a new dataset and loader from the previous dataset by splitting all digits and stacking them all together\n",
    "# such that the new dataset is of shape (number of total digits x 1 x 28 x 28)\n",
    "digits_train_dataset = None\n",
    "digits_train_loader = None\n",
    "digits_val_dataset = None\n",
    "digits_val_loader = None\n",
    "\n",
    "test_loader = DataLoader(X_test_processed, batch_size=4)\n",
    "\n",
    "# Class to represent our dataset and be used with dataloader\n",
    "class CustomMNISTDataset(TensorDataset):\n",
    "    def __init__(self):\n",
    "        self.len = len(X_train_processed)\n",
    "        self.x_data = X_train_processed\n",
    "        self.y_data = y_train_processed\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Class for our second CNN to predict the number of digits in an image\n",
    "class NumberOfDigitsDataset(TensorDataset):\n",
    "    def __init__(self):\n",
    "        self.len = len(X_train2)\n",
    "        self.x_data =scale(X_train2)\n",
    "        self.y_data = num_of_digits.to(torch.int64)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "print(X_train_processed[0].shape)\n",
    "print(X_train2[0].shape)\n",
    "dataset = CustomMNISTDataset()\n",
    "dataset2 = NumberOfDigitsDataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "train_loader2= torch.utils.data.DataLoader(dataset=dataset2, batch_size=4,\n",
    "                                          shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw X_train\n",
      "------\n",
      "\n",
      "Preprocessed X_train\n",
      "Label: tensor([ 1, 10, 10, 10, 10])\n",
      "Splitted\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Raw X_train')\n",
    "visualize_tensor(X_train[102])\n",
    "print('------\\n')\n",
    "print('Preprocessed X_train')\n",
    "x_sample, y_sample = next(iter(train_loader))\n",
    "print(f'Label: {y_sample[0]}')\n",
    "visualize_tensor(x_sample[0])\n",
    "print('Splitted')\n",
    "num_digits = torch.sum(y_sample[0] != 10).item()\n",
    "splitted_digits = split_digits(x_sample[0], num_digits)\n",
    "for digit in splitted_digits:\n",
    "    visualize_tensor(digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Convolutional neural network (Predict numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# TODO: STEP 1\n",
    "# Train a NN to predict num_digits in each sample. I.e. input would be X from num_digits_train_dataset, output would be\n",
    "# torch.sum(y[0] != 10).item()\n",
    "# This model should have accuracy very close to 100% (>99% on validation)\n",
    "# IF IT DOESN'T, MIGHT NEED DATA AUGMENTATION HERE\n",
    "# Track validation accuracy during training to avoid overfitting (stop training when\n",
    "# validation accuracy starts to decrease)\n",
    "# FANCY TIPS: Use batchnorm layers, lookup VGG/RESNET architecture\n",
    "\n",
    "# TODO: STEP 2\n",
    "# Train a NN to predict each 12x12 digit in digits_train_dataset\n",
    "# Track validation accuracy during training to avoid overfitting (stop training when\n",
    "# validation accuracy starts to decrease)\n",
    "# FANCY TIPS: Use batchnorm layers, lookup VGG/RESNET architecture\n",
    "\n",
    "# TODO: STEP 3\n",
    "# Make num_digits prediction for X_test based on model in STEP1, then use `split_digits()` function \n",
    "# with the predicted number of digits to split the digits, then make a prediction for each digit\n",
    "# separately by using the model trained in STEP 2. Convert the predictions from e.g. 2, 3\n",
    "# into the required format e.g. [2, 3, 10, 10, 10]\n",
    "\n",
    "# TODO: STEP 4\n",
    "# Convert predictions into whatever Excel format is required for uploading to Kaggle\n",
    "\n",
    "# TODO: EXTRA IMPROVEMENTS\n",
    "# - Data Augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Flatten(start_dim=1, end_dim=-1)\n",
      "  (4): Linear(in_features=1080, out_features=120, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=84, out_features=55, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0) # Ensure model weights initialized with same random numbers\n",
    "\n",
    "# # model 0\n",
    "# num_filters = 8\n",
    "# filter_size = 5\n",
    "# pool_size = 4\n",
    "\n",
    "# model = torch.nn.Sequential(\n",
    "#     torch.nn.Conv2d(in_channels=1,\n",
    "#                     out_channels=num_filters,\n",
    "#                     kernel_size=filter_size,\n",
    "#                     padding=filter_size // 2),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "#     torch.nn.Flatten(),\n",
    "#     torch.nn.Linear(num_filters * 64**2 // pool_size**2, 10),\n",
    "# )\n",
    "\n",
    "\n",
    "# model 1\n",
    "num_filters = [6, 16]\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "mlp_size = [16*14*14, 120, 84, 5 * 11]\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1,\n",
    "                    out_channels=num_filters[0],\n",
    "                    kernel_size=filter_size,\n",
    "                    padding=filter_size // 2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "    # torch.nn.Conv2d(in_channels=num_filters[0],\n",
    "    #                 out_channels=num_filters[1],\n",
    "    #                 kernel_size=filter_size,\n",
    "    #                 padding=filter_size // 2),\n",
    "    # torch.nn.ReLU(),\n",
    "    # torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(1080, mlp_size[1]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(mlp_size[1], mlp_size[2]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(mlp_size[2], mlp_size[3]),\n",
    ")\n",
    "\n",
    "\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loss function and Optimizer\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# cross entropy is pretty good for classification problems\n",
    "# discuss pros of cross entropy in the report\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# might need to play a bit with learning rate and momentum if needed\n",
    "# SGD is computationally efficient\n",
    "# GD is terrible, uses too much memory\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters())  # converges faster and less sensitive to lr, generalizes (typiaclly) worse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training CNN\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# loop over dataset multiple times\n",
    "# model.train()\n",
    "def train_model(model=model, train_loader=train_loader, custom_range=5):\n",
    "    for epoch in range(4):\n",
    "        running_loss = 0 # counter\n",
    "        # get inputs, data is a list of [inputs, labels]\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            # loss = criterion(outputs, labels)\n",
    "            loss = 0\n",
    "            for j in range(custom_range):\n",
    "                loss += criterion(outputs[:, (j * 11):((j + 1) * 11)], labels[:, j])\n",
    "\n",
    "            loss.backward() # computing gradients wrt model's weights\n",
    "            optimizer.step() # update using learning rate\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            # print every 2000 minibatches\n",
    "            if i % 2000 == 1999:\n",
    "                print('[%d, %5d loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss/2000))\n",
    "                running_loss = 0\n",
    "\n",
    "    print('Done')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_input = next(iter(test_loader))\n",
    "test_output = model(test_input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def output_to_label(output):\n",
    "    labels = [torch.argmax(output[:, (j * 11):((j + 1) * 11)], dim=1) for j in range(5)]\n",
    "    return torch.stack(labels)\n",
    "test_pred_labels = output_to_label(test_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 7,  0,  1,  0],\n        [10,  1,  6, 10],\n        [10,  7,  0, 10],\n        [10,  2,  2, 10],\n        [10, 10,  5, 10]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional neural network (Number of digits in image)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = [6, 16]\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "mlp_size = [4096, 120, 84, 5 * 11]\n",
    "\n",
    "model2 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1,\n",
    "                    out_channels=num_filters[0],\n",
    "                    kernel_size=filter_size,\n",
    "                    padding=filter_size // 2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "    torch.nn.Conv2d(in_channels=num_filters[0],\n",
    "                    out_channels=num_filters[1],\n",
    "                    kernel_size=filter_size,\n",
    "                    padding=filter_size // 2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(mlp_size[0], mlp_size[1]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(mlp_size[1], mlp_size[2]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(mlp_size[2], mlp_size[3]),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-76-ddf5a177cc6a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtrain_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrain_loader2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-50-950537244e12>\u001B[0m in \u001B[0;36mtrain_model\u001B[1;34m(model, train_loader)\u001B[0m\n\u001B[0;32m     13\u001B[0m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mj\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m                 \u001B[0mloss\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mj\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m11\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mj\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m11\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mj\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m             \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# computing gradients wrt model's weights\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "train_model(model=model2, train_loader=train_loader2, custom_range=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0) # Ensure model weights initialized with same random numbers\n",
    "\n",
    "# # model 0\n",
    "# num_filters = 8\n",
    "# filter_size = 5\n",
    "# pool_size = 4\n",
    "\n",
    "# model = torch.nn.Sequential(\n",
    "#     torch.nn.Conv2d(in_channels=1,\n",
    "#                     out_channels=num_filters,\n",
    "#                     kernel_size=filter_size,\n",
    "#                     padding=filter_size // 2),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "#     torch.nn.Flatten(),\n",
    "#     torch.nn.Linear(num_filters * 64**2 // pool_size**2, 10),\n",
    "# )\n",
    "\n",
    "\n",
    "# model 1\n",
    "num_filters = [6, 16]\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "mlp_size = [4096, 120, 84, 5 * 11]\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1,\n",
    "                    out_channels=num_filters[0],\n",
    "                    kernel_size=filter_size,\n",
    "                    padding=filter_size // 2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "    torch.nn.Conv2d(in_channels=num_filters[0],\n",
    "                    out_channels=num_filters[1],\n",
    "                    kernel_size=filter_size,\n",
    "                    padding=filter_size // 2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(720, mlp_size[1]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(mlp_size[1], mlp_size[2]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(mlp_size[2], mlp_size[3]),\n",
    ")\n",
    "\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loss function and Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy is pretty good for classification problems\n",
    "# discuss pros of cross entropy in the report\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# might need to play a bit with learning rate and momentum if needed\n",
    "# SGD is computationally efficient\n",
    "# GD is terrible, uses too much memory\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters())  # converges faster and less sensitive to lr, generalizes (typiaclly) worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop over dataset multiple times\n",
    "# model.train()\n",
    "for epoch in range(4):\n",
    "    running_loss = 0 # counter\n",
    "    # get inputs, data is a list of [inputs, labels]\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        # loss = criterion(outputs, labels)\n",
    "        loss = 0\n",
    "        for j in range(5):\n",
    "            loss += criterion(outputs[:, (j * 11):((j + 1) * 11)], labels[:, j])\n",
    "\n",
    "        loss.backward() # computing gradients wrt model's weights\n",
    "        optimizer.step() # update using learning rate\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # print every 2000 minibatches\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss/2000))\n",
    "            running_loss = 0\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_input = next(iter(test_loader))\n",
    "test_output = model(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_label(output):\n",
    "    labels = [torch.argmax(output[:, (j * 11):((j + 1) * 11)], dim=1) for j in range(5)]\n",
    "    return torch.stack(labels)\n",
    "test_pred_labels = output_to_label(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs, labels\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}