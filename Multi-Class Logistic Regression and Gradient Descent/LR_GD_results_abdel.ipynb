{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVIDSTH_Revised.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naghiman/AppliedMachineLearning/blob/master/Multi-Class%20Logistic%20Regression%20and%20Gradient%20Descent/LR_GD_results_abdel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ4ZrfbAs63i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f468db65-05e3-4f21-f22c-23db4d68c049"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "%matplotlib notebook\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.debugger import set_trace\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# if sklearn version is not up to date then\n",
        "# load_digits(as_frame=True) will fail \n",
        "# run these commands the first time to get version 0.24\n",
        "'''\n",
        "!pip uninstall scikit-learn -y\n",
        "\n",
        "!pip install Cython\n",
        "!pip install git+git://github.com/scikit-learn/scikit-learn.git\n",
        "!pip freeze | grep scikit\n",
        "'''\n",
        "\n",
        "import sklearn\n",
        "sklearn.__version__\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.24.dev0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT9457uos63p"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj8xgqDC8dtD"
      },
      "source": [
        "## 1. Digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjd7P36Qs63q",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e016a088-d038-41d0-f22b-50551ac40752"
      },
      "source": [
        "# LOAD AND PREPROCESS DIGITS DATASET\n",
        "\n",
        "digits = load_digits(as_frame=True)\n",
        "ddf = digits.frame\n",
        "y_digits = ddf['target'].to_numpy()\n",
        "ddf.drop(\"target\", axis=1, inplace=True)\n",
        "X_digits = ddf.to_numpy()\n",
        "\n",
        "print(f'X_digits.shape: {X_digits.shape}')\n",
        "print(f'y_digits.shape: {y_digits.shape}')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_digits.shape: (1797, 64)\n",
            "y_digits.shape: (1797,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InAizZ9D8dtJ"
      },
      "source": [
        "# train, val, test split\n",
        "X_trn_digits, X_tst_digits, y_trn_digits, y_tst_digits = sklearn.model_selection.train_test_split(X_digits, y_digits, test_size=1/5, random_state=0)\n",
        "X_trn_digits, X_val_digits, y_trn_digits, y_val_digits = sklearn.model_selection.train_test_split(X_trn_digits, y_trn_digits, test_size=1/4, random_state=0)\n",
        "\n",
        "# preprocess scales\n",
        "scaler_digits = sklearn.preprocessing.StandardScaler().fit(X_trn_digits)\n",
        "X_trn_digits = scaler_digits.transform(X_trn_digits)\n",
        "X_val_digits = scaler_digits.transform(X_val_digits)\n",
        "X_tst_digits = scaler_digits.transform(X_tst_digits)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SbhoR7f8dtO"
      },
      "source": [
        "## 2. Credit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QMhqQXus63u",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c10155-a961-4109-ba01-7729a3811ce9"
      },
      "source": [
        "# LOAD AND PREPROCESS CREDIT-G DATASET\n",
        "credit = fetch_openml(name='credit-g',as_frame=True)\n",
        "cdf = credit.frame\n",
        "\n",
        "# CONVERT CATEGORICAL FEATURES TO ONE-HOT ENCODING IN CREDIT-G\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc_df = pd.DataFrame(enc.fit_transform(cdf[['checking_status','credit_history','purpose','savings_status','employment','personal_status','other_parties','property_magnitude','other_payment_plans','housing','job','own_telephone','foreign_worker']]).toarray())\n",
        "cdf = cdf.join(enc_df)\n",
        "cdf.drop(['checking_status','credit_history','purpose','savings_status','employment','personal_status','other_parties','property_magnitude','other_payment_plans','housing','job','own_telephone','foreign_worker'], axis=1, inplace=True)\n",
        "class_dict = {\"bad\": 0, \"good\": 1}\n",
        "y_credit = (cdf.replace({\"class\": class_dict})['class']).to_numpy()\n",
        "cdf.drop(\"class\", axis=1, inplace=True)\n",
        "X_credit = cdf.to_numpy()\n",
        "\n",
        "print(f'X_credit.shape: {X_credit.shape}')\n",
        "print(f'y_credit.shape: {y_credit.shape}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_credit.shape: (1000, 61)\n",
            "y_credit.shape: (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_l1qFeT8dtV"
      },
      "source": [
        "# train, val, test split\n",
        "X_trn_credit, X_tst_credit, y_trn_credit, y_tst_credit = sklearn.model_selection.train_test_split(X_credit, y_credit, test_size=1/5, random_state=0)\n",
        "X_trn_credit, X_val_credit, y_trn_credit, y_val_credit = sklearn.model_selection.train_test_split(X_trn_credit, y_trn_credit, test_size=1/4, random_state=0)\n",
        "\n",
        "# preprocess scales\n",
        "scaler_credit = sklearn.preprocessing.StandardScaler().fit(X_trn_credit)\n",
        "X_trn_credit = scaler_credit.transform(X_trn_credit)\n",
        "X_val_credit = scaler_credit.transform(X_val_credit)\n",
        "X_tst_credit = scaler_credit.transform(X_tst_credit)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6zQNzZp8dta"
      },
      "source": [
        "# Softmax Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyDYhN5GRkHH"
      },
      "source": [
        "## Multi-class logistic regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJYNhFtY8dtc"
      },
      "source": [
        "class SoftmaxRegression:\n",
        "    def __init__(self, add_bias=True, reg=0):\n",
        "        self.add_bias = add_bias\n",
        "        self.reg = reg\n",
        "\n",
        "    def fit(self, x, y, optimizer):\n",
        "        if x.ndim == 1:\n",
        "            x = x[:, None]\n",
        "        if self.add_bias:\n",
        "            N = x.shape[0]\n",
        "            x = np.column_stack([x, np.ones(N)])\n",
        "        N,D = x.shape\n",
        "        C = len(np.unique(y))\n",
        "\n",
        "        def gradient(x, y, w):                          # define the gradient function\n",
        "            N = x.shape[0]\n",
        "\n",
        "            # Softmax calculation\n",
        "            scores = x.dot(w)\n",
        "            scores -= np.max(scores, axis=1, keepdims=True)\n",
        "            exp_scores = np.exp(scores)\n",
        "            softmax = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "            # dw calculation\n",
        "            indices = np.arange(N)\n",
        "            softmax_editted = softmax\n",
        "            softmax_editted[indices, y] -= 1\n",
        "            dw = np.dot(x.T, softmax_editted)\n",
        "            dw /= N\n",
        "            dw += self.reg * 2 * w\n",
        "            return dw\n",
        "\n",
        "        w0 = np.zeros((D, C))                                # initialize the weights to 0\n",
        "        self.w = optimizer.run(gradient, x, y, w0)      # run the optimizer to get the optimal weights\n",
        "        print(self.w.shape)\n",
        "        return self\n",
        "    \n",
        "    def predict(self, x):\n",
        "        if self.add_bias:\n",
        "            x = np.column_stack([x, np.ones(x.shape[0])])\n",
        "        yh = x@self.w\n",
        "        y_pred = np.argmax(yh, axis=1)\n",
        "        return y_pred"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsGmJKHqRkHH"
      },
      "source": [
        "## Mini-batch optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETd2_GHO8dti"
      },
      "source": [
        "class MiniBatchGradientMomentum:\n",
        "    def __init__(self, learning_rate=.001, batch_size=16, momentum=0.9, max_iters=1e4, epsilon=1e-8, record_history=False):\n",
        "      self.learning_rate = learning_rate\n",
        "      self.max_iters = max_iters\n",
        "      self.record_history = record_history\n",
        "      self.epsilon = epsilon\n",
        "      self.momentum = momentum\n",
        "      self.batch_size = batch_size\n",
        "      if record_history:\n",
        "          self.w_history = []                \n",
        "\n",
        "    def run(self, gradient_fn, x, y, w):\n",
        "      grad = np.inf\n",
        "      t = 1\n",
        "      delta_w = 0\n",
        "      while np.linalg.norm(grad) > self.epsilon and t < self.max_iters:\n",
        "          batch_inds = np.random.choice(x.shape[0], self.batch_size)\n",
        "          grad = gradient_fn(x[batch_inds], y[batch_inds], w)\n",
        "          delta_w = self.momentum * delta_w + (1 - self.momentum) * grad              \n",
        "          w = w - self.learning_rate * delta_w       \n",
        "          if self.record_history:\n",
        "              self.w_history.append(w)\n",
        "          t += 1\n",
        "      return w"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvekvffQ8dtn"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk1tVUsG8dto"
      },
      "source": [
        "## 1. Digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL5_hF7K8dtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "437c0f1d-ddd1-4a6f-e85c-1ebb89933768"
      },
      "source": [
        "optimizer = MiniBatchGradientMomentum(learning_rate=.005, max_iters=1000, batch_size=16, record_history=True)\n",
        "model = SoftmaxRegression()\n",
        "model.fit(X_trn_digits, y_trn_digits, optimizer)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(65, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.SoftmaxRegression at 0x7f5533fa7e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyjFrjTz8dtt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeef50b8-f03a-4b5e-c875-04778ff683b4"
      },
      "source": [
        "train_acc_digits = sklearn.metrics.accuracy_score(y_trn_digits, model.predict(X_trn_digits))\n",
        "val_acc_digits = sklearn.metrics.accuracy_score(y_val_digits, model.predict(X_val_digits))\n",
        "test_acc_digits = sklearn.metrics.accuracy_score(y_tst_digits, model.predict(X_tst_digits))\n",
        "print(f'Digits train accuracy: {train_acc_digits}')\n",
        "print(f'Digits validation accuracy: {val_acc_digits}')\n",
        "print(f'Digits test accuracy: {test_acc_digits}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Digits train accuracy: 0.9396471680594243\n",
            "Digits validation accuracy: 0.9055555555555556\n",
            "Digits test accuracy: 0.9194444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSVGfhsZ8dtw"
      },
      "source": [
        "## 2. Credit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfrMJJ8n8dtx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e9d470a-5cce-4ba1-c193-2090ade8c810"
      },
      "source": [
        "optimizer = MiniBatchGradientMomentum(learning_rate=.005, max_iters=1000, batch_size=16, record_history=True)\n",
        "model = SoftmaxRegression()\n",
        "model.fit(X_trn_credit, y_trn_credit, optimizer)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(62, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.SoftmaxRegression at 0x7f5533fa7fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRxV3cVW8dt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d575ceb-fe44-41f5-f6c0-2ecdec4c2738"
      },
      "source": [
        "train_acc_credit = sklearn.metrics.accuracy_score(y_trn_credit, model.predict(X_trn_credit))\n",
        "val_acc_credit = sklearn.metrics.accuracy_score(y_val_credit, model.predict(X_val_credit))\n",
        "test_acc_credit = sklearn.metrics.accuracy_score(y_tst_credit, model.predict(X_tst_credit))\n",
        "print(f'Credit-G train accuracy: {train_acc_credit}')\n",
        "print(f'Credit-G validation accuracy: {val_acc_credit}')\n",
        "print(f'Credit-G test accuracy: {test_acc_credit}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Credit-G train accuracy: 0.7983333333333333\n",
            "Credit-G validation accuracy: 0.76\n",
            "Credit-G test accuracy: 0.725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imLadUGas64J"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8eLdP3ThW03"
      },
      "source": [
        "\n",
        "# softmax class is refactored a bit, predict method moved to optimizer class\n",
        "# validation sets given as parameters to calculate accuracy for each iteration\n",
        "class SoftmaxRegression:\n",
        "    def __init__(self, add_bias=True, reg=0):\n",
        "        self.add_bias = add_bias\n",
        "        self.reg = reg\n",
        "\n",
        "    def fit(self, x, y, X_val, y_val, optimizer, limit):\n",
        "        if x.ndim == 1:\n",
        "            x = x[:, None]\n",
        "        if self.add_bias:\n",
        "            N = x.shape[0]\n",
        "            x = np.column_stack([x, np.ones(N)])\n",
        "        N,D = x.shape\n",
        "        C = len(np.unique(y))\n",
        "\n",
        "        def gradient(x, y, w):                          # define the gradient function\n",
        "            N = x.shape[0]\n",
        "\n",
        "            # Softmax calculation\n",
        "            scores = x.dot(w)\n",
        "            scores -= np.max(scores, axis=1, keepdims=True)\n",
        "            exp_scores = np.exp(scores)\n",
        "            softmax = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "            # dw calculation\n",
        "            indices = np.arange(N)\n",
        "            softmax_editted = softmax\n",
        "            softmax_editted[indices, y] -= 1\n",
        "            dw = np.dot(x.T, softmax_editted)\n",
        "            dw /= N\n",
        "            dw += self.reg * 2 * w\n",
        "            return dw\n",
        "\n",
        "        w0 = np.zeros((D, C))                                                # initialize the weights to 0\n",
        "        self.w = optimizer.run(gradient, x, y, w0, X_val, y_val, limit)      # run the optimizer to get the optimal weights      \n",
        "        return self\n",
        "\n",
        "\n",
        "class MiniBatchGradientMomentum:\n",
        "    def __init__(self, add_bias=True, learning_rate=.001, batch_size=16, momentum=0.9, max_iters=25000, epsilon=1e-8, record_history=False):\n",
        "      self.add_bias = add_bias\n",
        "      self.learning_rate = learning_rate\n",
        "      self.max_iters = max_iters\n",
        "      self.record_history = record_history\n",
        "      self.epsilon = epsilon\n",
        "      self.momentum = momentum\n",
        "      self.batch_size = batch_size\n",
        "      if record_history:\n",
        "          self.w_history = []                \n",
        "\n",
        "    def run(self, gradient_fn, x, y, w, X_val, y_val, limit):\n",
        "      grad = np.inf\n",
        "      t = 1\n",
        "      delta_w = 0\n",
        "      val_accs = []\n",
        "\n",
        "      # need at least (limit) iterations to look at\n",
        "      # check validation accuracy values have not decreased for last (limit) iterations\n",
        "      # add a max iterations check so we don't loop forever in case 2 conditions above fail to stop loop\n",
        "      while t < self.max_iters and (t < limit or not self.decreasing(val_accs, t, limit, self.epsilon)):\n",
        "          batch_inds = np.random.choice(x.shape[0], self.batch_size)\n",
        "          grad = gradient_fn(x[batch_inds], y[batch_inds], w)\n",
        "          delta_w = self.momentum * delta_w + (1 - self.momentum) * grad              \n",
        "          w = w - self.learning_rate * delta_w       \n",
        "          if self.record_history:\n",
        "              self.w_history.append(w)\n",
        "          val_acc = sklearn.metrics.accuracy_score(y_val, self.predict(X_val, w))\n",
        "          val_accs.append(val_acc)\n",
        "          t += 1\n",
        "      \n",
        "      # it is possible the last (limit) iterations happened at the exact so we need an extra check\n",
        "      # for non decreasing values\n",
        "      if t == self.max_iters and not self.decreasing(val_accs, t-1, limit, self.epsilon):\n",
        "        print(f'best validation accuracy ({val_acc}) overshoot to the maximum {t} iterations based on last {limit} values')\n",
        "      else:\n",
        "        print(f'best validation accuracy ({val_acc}) found after {t} iterations based on last {limit} values')\n",
        "\n",
        "      # since we stored accuracy values at each iteration we can compare with the real best value\n",
        "      print(f'true best result is {max(val_accs)} which happened after {val_accs.index(max(val_accs))} iterations')\n",
        "      return w\n",
        "    \n",
        "    def decreasing(self, values, t, limit, epsilon):\n",
        "      return all(0<=x-y<=epsilon for x, y in zip(values[t-limit:t], values[t-limit+1:t+1]))\n",
        "\n",
        "    def predict(self, x, w):\n",
        "      if self.add_bias:\n",
        "          x = np.column_stack([x, np.ones(x.shape[0])])\n",
        "      yh = x@w\n",
        "      y_pred = np.argmax(yh, axis=1)\n",
        "      return y_pred"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDsD0iV2jvJt",
        "outputId": "0b741c32-66aa-4aec-fa5d-82f294a5ef32"
      },
      "source": [
        "model = SoftmaxRegression()\n",
        "\n",
        "print(\"for credit dataset\")\n",
        "optimizer = MiniBatchGradientMomentum(learning_rate=.005, max_iters=5000, batch_size=16, record_history=True)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 20)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 50)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 100)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 150)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 200)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 400)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 800)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 2000)\n",
        "\n",
        "optimizer = MiniBatchGradientMomentum(learning_rate=.005, max_iters=50000, batch_size=16, record_history=True)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 20)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 50)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 100)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 150)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 200)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 400)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 800)\n",
        "model.fit(X_trn_credit, y_trn_credit, X_val_credit, y_val_credit, optimizer, 2000)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for credit dataset\n",
            "best validation accuracy (0.765) found after 316 iterations based on last 20 values\n",
            "true best result is 0.785 which happened after 98 iterations\n",
            "best validation accuracy (0.77) found after 539 iterations based on last 50 values\n",
            "true best result is 0.775 which happened after 86 iterations\n",
            "best validation accuracy (0.765) found after 2627 iterations based on last 100 values\n",
            "true best result is 0.785 which happened after 88 iterations\n",
            "best validation accuracy (0.77) overshoot to the maximum 5000 iterations based on last 150 values\n",
            "true best result is 0.785 which happened after 22 iterations\n",
            "best validation accuracy (0.77) overshoot to the maximum 5000 iterations based on last 200 values\n",
            "true best result is 0.775 which happened after 344 iterations\n",
            "best validation accuracy (0.76) overshoot to the maximum 5000 iterations based on last 400 values\n",
            "true best result is 0.78 which happened after 44 iterations\n",
            "best validation accuracy (0.775) overshoot to the maximum 5000 iterations based on last 800 values\n",
            "true best result is 0.79 which happened after 147 iterations\n",
            "best validation accuracy (0.76) overshoot to the maximum 5000 iterations based on last 2000 values\n",
            "true best result is 0.78 which happened after 1005 iterations\n",
            "best validation accuracy (0.75) found after 164 iterations based on last 20 values\n",
            "true best result is 0.75 which happened after 144 iterations\n",
            "best validation accuracy (0.785) found after 673 iterations based on last 50 values\n",
            "true best result is 0.79 which happened after 382 iterations\n",
            "best validation accuracy (0.76) found after 2129 iterations based on last 100 values\n",
            "true best result is 0.795 which happened after 170 iterations\n",
            "best validation accuracy (0.76) found after 3766 iterations based on last 150 values\n",
            "true best result is 0.785 which happened after 2564 iterations\n",
            "best validation accuracy (0.755) found after 26638 iterations based on last 200 values\n",
            "true best result is 0.79 which happened after 17318 iterations\n",
            "best validation accuracy (0.78) overshoot to the maximum 50000 iterations based on last 400 values\n",
            "true best result is 0.785 which happened after 254 iterations\n",
            "best validation accuracy (0.77) overshoot to the maximum 50000 iterations based on last 800 values\n",
            "true best result is 0.79 which happened after 12602 iterations\n",
            "best validation accuracy (0.76) overshoot to the maximum 50000 iterations based on last 2000 values\n",
            "true best result is 0.785 which happened after 486 iterations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.SoftmaxRegression at 0x7f5533fac240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YciQwafw71Bm",
        "outputId": "0218b2f4-4952-43ed-df6b-682ce8a568b8"
      },
      "source": [
        "print(\"for digits dataset\")\n",
        "optimizer = MiniBatchGradientMomentum(learning_rate=.005, max_iters=5000, batch_size=16, record_history=True)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 20)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 50)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 100)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 150)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 200)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 400)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 800)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 2000)\n",
        "\n",
        "optimizer = MiniBatchGradientMomentum(learning_rate=.005, max_iters=50000, batch_size=16, record_history=True)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 20)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 50)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 100)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 150)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 200)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 400)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 800)\n",
        "model.fit(X_trn_digits, y_trn_digits, X_val_digits, y_val_digits, optimizer, 2000)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for digits dataset\n",
            "best validation accuracy (0.8694444444444445) found after 161 iterations based on last 20 values\n",
            "true best result is 0.8722222222222222 which happened after 66 iterations\n",
            "best validation accuracy (0.8861111111111111) found after 495 iterations based on last 50 values\n",
            "true best result is 0.8861111111111111 which happened after 392 iterations\n",
            "best validation accuracy (0.9) found after 678 iterations based on last 100 values\n",
            "true best result is 0.9055555555555556 which happened after 514 iterations\n",
            "best validation accuracy (0.9027777777777778) found after 940 iterations based on last 150 values\n",
            "true best result is 0.9055555555555556 which happened after 579 iterations\n",
            "best validation accuracy (0.9416666666666667) found after 3054 iterations based on last 200 values\n",
            "true best result is 0.9416666666666667 which happened after 2629 iterations\n",
            "best validation accuracy (0.9444444444444444) overshoot to the maximum 5000 iterations based on last 400 values\n",
            "true best result is 0.9472222222222222 which happened after 3498 iterations\n",
            "best validation accuracy (0.95) overshoot to the maximum 5000 iterations based on last 800 values\n",
            "true best result is 0.95 which happened after 3713 iterations\n",
            "best validation accuracy (0.95) overshoot to the maximum 5000 iterations based on last 2000 values\n",
            "true best result is 0.95 which happened after 4253 iterations\n",
            "best validation accuracy (0.8555555555555555) found after 200 iterations based on last 20 values\n",
            "true best result is 0.8555555555555555 which happened after 38 iterations\n",
            "best validation accuracy (0.8944444444444445) found after 523 iterations based on last 50 values\n",
            "true best result is 0.8944444444444445 which happened after 448 iterations\n",
            "best validation accuracy (0.9027777777777778) found after 693 iterations based on last 100 values\n",
            "true best result is 0.9027777777777778 which happened after 593 iterations\n",
            "best validation accuracy (0.9) found after 1021 iterations based on last 150 values\n",
            "true best result is 0.9027777777777778 which happened after 811 iterations\n",
            "best validation accuracy (0.9333333333333333) found after 2702 iterations based on last 200 values\n",
            "true best result is 0.9361111111111111 which happened after 2304 iterations\n",
            "best validation accuracy (0.9472222222222222) found after 5189 iterations based on last 400 values\n",
            "true best result is 0.95 which happened after 4468 iterations\n",
            "best validation accuracy (0.95) found after 6418 iterations based on last 800 values\n",
            "true best result is 0.9527777777777777 which happened after 4635 iterations\n",
            "best validation accuracy (0.9555555555555556) found after 10799 iterations based on last 2000 values\n",
            "true best result is 0.9555555555555556 which happened after 8799 iterations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.SoftmaxRegression at 0x7f5533fac518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}