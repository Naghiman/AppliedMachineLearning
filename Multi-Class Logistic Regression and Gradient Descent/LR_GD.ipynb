{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FQ4ZrfbAs63i"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.debugger import set_trace\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DT9457uos63p"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Qjd7P36Qs63q",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_digits.shape: (1797, 64)\n",
      "y_digits.shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "# LOAD AND PREPROCESS DIGITS DATASET\n",
    "digits = load_digits(as_frame=True)\n",
    "ddf = digits.frame\n",
    "y_digits = ddf['target'].to_numpy()\n",
    "ddf.drop(\"target\", axis=1, inplace=True)\n",
    "X_digits = ddf.to_numpy()\n",
    "\n",
    "print(f'X_digits.shape: {X_digits.shape}')\n",
    "print(f'y_digits.shape: {y_digits.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val, test split\n",
    "X_trn_digits, X_tst_digits, y_trn_digits, y_tst_digits = sklearn.model_selection.train_test_split(X_digits, y_digits, test_size=1/5, random_state=0)\n",
    "X_trn_digits, X_val_digits, y_trn_digits, y_val_digits = sklearn.model_selection.train_test_split(X_trn_digits, y_trn_digits, test_size=1/4, random_state=0)\n",
    "\n",
    "# preprocess scales\n",
    "scaler_digits = sklearn.preprocessing.StandardScaler().fit(X_trn_digits)\n",
    "X_trn_digits = scaler_digits.transform(X_trn_digits)\n",
    "X_val_digits = scaler_digits.transform(X_val_digits)\n",
    "X_tst_digits = scaler_digits.transform(X_tst_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8QMhqQXus63u",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_credit.shape: (1000, 61)\n",
      "y_credit.shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# LOAD AND PREPROCESS CREDIT-G DATASET\n",
    "credit = fetch_openml(name='credit-g',as_frame=True)\n",
    "cdf = credit.frame\n",
    "\n",
    "# CONVERT CATEGORICAL FEATURES TO ONE-HOT ENCODING IN CREDIT-G\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(cdf[['checking_status','credit_history','purpose','savings_status','employment','personal_status','other_parties','property_magnitude','other_payment_plans','housing','job','own_telephone','foreign_worker']]).toarray())\n",
    "cdf = cdf.join(enc_df)\n",
    "cdf.drop(['checking_status','credit_history','purpose','savings_status','employment','personal_status','other_parties','property_magnitude','other_payment_plans','housing','job','own_telephone','foreign_worker'], axis=1, inplace=True)\n",
    "class_dict = {\"bad\": 0, \"good\": 1}\n",
    "y_credit = (cdf.replace({\"class\": class_dict})['class']).to_numpy()\n",
    "cdf.drop(\"class\", axis=1, inplace=True)\n",
    "X_credit = cdf.to_numpy()\n",
    "\n",
    "print(f'X_credit.shape: {X_credit.shape}')\n",
    "print(f'y_credit.shape: {y_credit.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val, test split\n",
    "X_trn_credit, X_tst_credit, y_trn_credit, y_tst_credit = sklearn.model_selection.train_test_split(X_credit, y_credit, test_size=1/5, random_state=0)\n",
    "X_trn_credit, X_val_credit, y_trn_credit, y_val_credit = sklearn.model_selection.train_test_split(X_trn_credit, y_trn_credit, test_size=1/4, random_state=0)\n",
    "\n",
    "# preprocess scales\n",
    "scaler_credit = sklearn.preprocessing.StandardScaler().fit(X_trn_credit)\n",
    "X_trn_credit = scaler_credit.transform(X_trn_credit)\n",
    "X_val_credit = scaler_credit.transform(X_val_credit)\n",
    "X_tst_credit = scaler_credit.transform(X_tst_credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression:\n",
    "    def __init__(self, add_bias=True, reg=0):\n",
    "        self.add_bias = add_bias\n",
    "        self.reg = reg\n",
    "\n",
    "    def fit(self, x, y, optimizer):\n",
    "        if x.ndim == 1:\n",
    "            x = x[:, None]\n",
    "        if self.add_bias:\n",
    "            N = x.shape[0]\n",
    "            x = np.column_stack([x, np.ones(N)])\n",
    "        N,D = x.shape\n",
    "        C = len(np.unique(y))\n",
    "\n",
    "        def gradient(x, y, w):                          # define the gradient function\n",
    "            N = x.shape[0]\n",
    "\n",
    "            # Softmax calculation\n",
    "            scores = x.dot(w)\n",
    "            scores -= np.max(scores, axis=1, keepdims=True)\n",
    "            exp_scores = np.exp(scores)\n",
    "            softmax = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "            # dw calculation\n",
    "            indices = np.arange(N)\n",
    "            softmax_editted = softmax\n",
    "            softmax_editted[indices, y] -= 1\n",
    "            dw = np.dot(x.T, softmax_editted)\n",
    "            dw /= N\n",
    "            dw += self.reg * 2 * w\n",
    "            return dw\n",
    "\n",
    "        w0 = np.zeros((D, C))                                # initialize the weights to 0\n",
    "        self.w = optimizer.run(gradient, x, y, w0)      # run the optimizer to get the optimal weights\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.add_bias:\n",
    "            x = np.column_stack([x, np.ones(x.shape[0])])\n",
    "        yh = x@self.w\n",
    "        y_pred = np.argmax(yh, axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent:\n",
    "    def __init__(self, learning_rate=.001, max_iters=1e4, epsilon=1e-8, record_history=False):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iters = max_iters\n",
    "        self.record_history = record_history\n",
    "        self.epsilon = epsilon\n",
    "        if record_history:\n",
    "            self.w_history = []                 #to store the weight history for visualization\n",
    "            \n",
    "    def run(self, gradient_fn, x, y, w):\n",
    "        grad = np.inf\n",
    "        t = 1\n",
    "        while np.linalg.norm(grad) > self.epsilon and t < self.max_iters:\n",
    "            grad = gradient_fn(x, y, w)               # compute the gradient with present weight\n",
    "            w = w - self.learning_rate * grad         # weight update step\n",
    "            if self.record_history:\n",
    "                self.w_history.append(w)\n",
    "            t += 1\n",
    "        return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SoftmaxRegression at 0x1a22fce630>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = GradientDescent(learning_rate=.005, max_iters=100, record_history=True)\n",
    "model = SoftmaxRegression()\n",
    "model.fit(X_trn_digits, y_trn_digits, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits train accuracy: 0.8662952646239555\n",
      "Digits validation accuracy: 0.8583333333333333\n",
      "Digits test accuracy: 0.8305555555555556\n"
     ]
    }
   ],
   "source": [
    "train_acc_digits = sklearn.metrics.accuracy_score(y_trn_digits, model.predict(X_trn_digits))\n",
    "val_acc_digits = sklearn.metrics.accuracy_score(y_val_digits, model.predict(X_val_digits))\n",
    "test_acc_digits = sklearn.metrics.accuracy_score(y_tst_digits, model.predict(X_tst_digits))\n",
    "print(f'Digits train accuracy: {train_acc_digits}')\n",
    "print(f'Digits validation accuracy: {val_acc_digits}')\n",
    "print(f'Digits test accuracy: {test_acc_digits}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SoftmaxRegression at 0x1a22fced30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = GradientDescent(learning_rate=.005, max_iters=100, record_history=True)\n",
    "model = SoftmaxRegression()\n",
    "model.fit(X_trn_credit, y_trn_credit, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit-G train accuracy: 0.7883333333333333\n",
      "Credit-G validation accuracy: 0.765\n",
      "Credit-G test accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "train_acc_credit = sklearn.metrics.accuracy_score(y_trn_credit, model.predict(X_trn_credit))\n",
    "val_acc_credit = sklearn.metrics.accuracy_score(y_val_credit, model.predict(X_val_credit))\n",
    "test_acc_credit = sklearn.metrics.accuracy_score(y_tst_credit, model.predict(X_tst_credit))\n",
    "print(f'Credit-G train accuracy: {train_acc_credit}')\n",
    "print(f'Credit-G validation accuracy: {val_acc_credit}')\n",
    "print(f'Credit-G test accuracy: {test_acc_credit}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imLadUGas64J"
   },
   "source": [
    "# Mini-batch optimization using gradient descent"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "COVIDSTH_Revised.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
